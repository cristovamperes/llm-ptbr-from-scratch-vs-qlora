{
  "tokenization": "sentencepiece",
  "tokenizer_model": "/workspace/TCC/versions/v6-release-candidate/tokenizers/unigram_16k/spm_v6.model",
  "tokenizer_vocab_size": 14500,
  "sequence_length": 256,
  "stride": 48,
  "batch_size": 64,
  "add_bos": true,
  "add_eos": true,
  "model": {
    "d_model": 512,
    "num_layers": 6,
    "num_heads": 8,
    "d_ff": 2048,
    "dropout": 0.1
  }
}